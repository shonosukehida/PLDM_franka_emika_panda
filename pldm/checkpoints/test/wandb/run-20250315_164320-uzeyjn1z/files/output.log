Loaded offline data with 3072000 samples
Data episode length: 16
Episode length: 16
Slices per traj: 75
3072000 samples in offline_wall dataset
estimating mean stds: 100%|██████████| 100/100 [00:01<00:00, 86.16it/s]
Inferred input_dim: torch.Size([2, 65, 65])
HJEPA(
  (level1): JEPA(
    (backbone): ImpalaEncoder(
      (stack_blocks): ModuleList(
        (0): ResnetStack(
          (initial_conv): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (blocks): ModuleList(
            (0-1): 2 x ResnetBlock(
              (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (1): ResnetStack(
          (initial_conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (blocks): ModuleList(
            (0-1): 2 x ResnetBlock(
              (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (2): ResnetStack(
          (initial_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (blocks): ModuleList(
            (0-1): 2 x ResnetBlock(
              (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
      )
      (dropout): Identity()
      (mlp): Linear(in_features=2592, out_features=512, bias=True)
      (final_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (predictor): RNNPredictorV2(
      (final_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (rnn): GRU(2, 512)
    )
  )
)
number of params: 2218672
number of l1 predictor params: 793600
number of l1 backbone params: 1426096
compiling model
compilation finished after 1.100s
Loss: 1.1259, train: 0.042s, data: 0.058s, log: 0.001s:  58%|█████▊    | 27837/48000 [47:01<34:04,  9.86it/s]
Epoch:   0%|          | 0/3 [47:01<?, ?it/s]og: 0.001s:  58%|█████▊    | 27837/48000 [47:01<33:59,  9.89it/s]  
Traceback (most recent call last):
  File "/home/hida/PLDM/pldm/train.py", line 573, in <module>
    main(cfg)
  File "/home/hida/PLDM/pldm/train.py", line 565, in main
    trainer.train()
  File "/home/hida/PLDM/pldm/train.py", line 347, in train
    for step, batch in (
  File "/home/hida/PLDM/.venv/lib/python3.11/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/hida/PLDM/pldm/data/utils.py", line 100, in __iter__
    for batch in self.dataloader:
  File "/home/hida/PLDM/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/hida/PLDM/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 764, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hida/PLDM/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hida/PLDM/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/hida/PLDM/pldm_envs/wall/data/offline_wall.py", line 112, in __getitem__
    ).to(self.device)
      ^^^^^^^^^^^^^^^
KeyboardInterrupt
